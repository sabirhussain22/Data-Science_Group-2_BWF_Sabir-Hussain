{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03db0389-fd04-4262-84fc-fa7fd72cc957",
   "metadata": {},
   "source": [
    "# <b><p style=\"background-color: #ff6200; font-family:calibri; color:white; font-size:100%; font-family:Verdana; text-align:center; border-radius:15px 50px;\">Task 29-> Hyperparameter Tuning Techniques</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cab9a6-89cd-443d-8b8d-6f6a8fb002a0",
   "metadata": {},
   "source": [
    "# Hyperparameter Tunning\n",
    "Hyperparameter tuning is the process of optimizing the hyperparameters of a machine learning model to improve its performance. Hyperparameters are configuration settings used to control the training process, such as learning rate, batch size, and the number of layers in a neural network. Unlike model parameters, which are learned during training, hyperparameters must be set before the learning process begins. The goal of hyperparameter tuning is to find the best combination of hyperparameters that result in the highest model accuracy or lowest error rate. This process can be computationally intensive and may involve techniques such as grid search, random search, or more sophisticated methods like Bayesian optimization and evolutionary algorithms. Effective hyperparameter tuning can significantly enhance the predictive power of a model, making it more accurate and reliable. It is a crucial step in the machine learning pipeline, particularly for complex models and large datasets.\n",
    "\n",
    "## Tasks:\n",
    "1. [Grid Search](#1)\n",
    "    -  [Regression Model](#01)\n",
    "    -  [Classification Model](#11)\n",
    "2. [Random Search](#2)\n",
    "    -  [Regression Model](#02)\n",
    "    -  [Classification Model](#12)\n",
    "3. [Bayesian Optimization](#3)\n",
    "    -  [Regression Model](#03)\n",
    "    -  [Classification Model](#13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d27ef7-8ef2-444d-899a-fa2ecf495b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fac407-2d4f-45a9-b018-e0c6ee600177",
   "metadata": {},
   "source": [
    "## <span style='color:#ff6200'> Importing Libraries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab79da6-5816-406f-b7d9-76a08dbb2434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5e89a3-1d03-4a69-a266-4f32018523c3",
   "metadata": {},
   "source": [
    "## <span style='color:#ff6200'> Load and Process Regression Dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da5056c6-9f55-4d42-b80d-59d2264d2beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours Studied</th>\n",
       "      <th>Previous Scores</th>\n",
       "      <th>Extracurricular Activities</th>\n",
       "      <th>Sleep Hours</th>\n",
       "      <th>Sample Question Papers Practiced</th>\n",
       "      <th>Performance Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hours Studied  Previous Scores  Extracurricular Activities  Sleep Hours  \\\n",
       "0              7               99                           1            9   \n",
       "1              4               82                           0            4   \n",
       "2              8               51                           1            7   \n",
       "3              5               52                           1            5   \n",
       "4              7               75                           0            8   \n",
       "\n",
       "   Sample Question Papers Practiced  Performance Index  \n",
       "0                                 1               91.0  \n",
       "1                                 2               65.0  \n",
       "2                                 2               45.0  \n",
       "3                                 2               36.0  \n",
       "4                                 5               66.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_df = pd.read_csv(\"Student_Performance.csv\")\n",
    "regression_df['Extracurricular Activities'] = regression_df['Extracurricular Activities'].map({'No': 0, 'Yes': 1})\n",
    "regression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "649f7f6d-6bce-45b2-bb33-25a673f7e882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 5), (2000, 5), (8000,), (2000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_r = regression_df.drop('Performance Index',axis=1)\n",
    "y_r = regression_df['Performance Index']\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X_r, y_r, test_size=0.2)\n",
    "X_train_r.shape, X_test_r.shape, y_train_r.shape, y_test_r.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924efd03-ca1a-4546-83eb-5b5ca501e9cf",
   "metadata": {},
   "source": [
    "## <span style='color:#ff6200'> Load and Process Classification Dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c209ddf8-d49f-496f-9494-198fe04296ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RI     Na    Mg    Al     Si     K    Ca   Ba   Fe  Type\n",
       "0  1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.0  0.0     1\n",
       "1  1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.0  0.0     1\n",
       "2  1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.0  0.0     1\n",
       "3  1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.0  0.0     1\n",
       "4  1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.0  0.0     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_df = pd.read_csv(\"glass.csv\")\n",
    "classification_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9fbbf76-afa2-43ad-aa28-e59006484b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((171, 9), (43, 9), (171,), (43,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c = classification_df.drop('Type',axis=1)\n",
    "y_c = classification_df['Type']\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_c, y_c, test_size=0.2)\n",
    "X_train_c.shape, X_test_c.shape, y_train_c.shape, y_test_c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e620652-1e03-4829-986a-1f692a0122c0",
   "metadata": {},
   "source": [
    "## Some Hyperparameter Tuning Techniques\n",
    "- Grid Search\n",
    "- Random Search\n",
    "- Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd5c0a5-3833-4411-acc4-f9a263734780",
   "metadata": {},
   "source": [
    "# <b><span style='color:#ff6200'> Grid Search</span>\n",
    "\n",
    "Grid Search involves an exhaustive search over a specified parameter grid. It systematically works through multiple combinations of hyperparameters, cross-validating as it goes to determine which set of values provides the best model performance.\n",
    "## Procedure:\n",
    "\n",
    "- Define the range of values for each hyperparameter.\n",
    "- Create a grid of all possible combinations.\n",
    "- Train and evaluate the model for each combination using cross-validation.\n",
    "- Select the combination with the best performance.\n",
    "## Pros:\n",
    "\n",
    "- Simple to understand and implement.\n",
    "- Guarantees finding the best combination of parameters within the grid.\n",
    "## Cons:\n",
    "\n",
    "- Computationally expensive, especially when dealing with large datasets and many hyperparameters.\n",
    "- Inefficient as it does not use any information from previous evaluations to decide the next set of parameters to try."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f61a43-f4ef-47ee-a44a-3986f32a5235",
   "metadata": {},
   "source": [
    "## <span style='color:#fcc36d'> For Regression </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb378770-28a5-401d-8af8-04c528b865a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model = DecisionTreeRegressor()\n",
    "simple_model.fit(X_train_r, y_train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9bcf913-5c95-4a99-a3b0-9fd6c522b46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Decision Tree - MSE: 8.595402777777778, R2: 0.976647045730854\n"
     ]
    }
   ],
   "source": [
    "y_pred_simple = simple_model.predict(X_test_r)\n",
    "mse_simple = mean_squared_error(y_test_r, y_pred_simple)\n",
    "r2_simple = r2_score(y_test_r, y_pred_simple)\n",
    "print(f\"Simple Decision Tree - MSE: {mse_simple}, R2: {r2_simple}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9998b798-53d9-4332-a967-752fd27f36a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Decision Tree: {'max_depth': 10, 'max_features': None, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "\n",
      "Best Decision Tree With Grid Search - MSE: 5.802518915814977, R2: 0.9842350658380764\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_r, y_train_r)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters for Decision Tree:\", best_params)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_test = best_model.predict(X_test_r)\n",
    "\n",
    "mse_test = mean_squared_error(y_test_r, y_pred_test)\n",
    "r2_test = r2_score(y_test_r, y_pred_test)\n",
    "\n",
    "print(f\"\\nBest Decision Tree With Grid Search - MSE: {mse_test}, R2: {r2_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e1d0b-f11a-4132-96a7-d22abc471389",
   "metadata": {},
   "source": [
    "## <span style='color:#fcc36d'> For Classification </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c452991f-e128-49da-8907-9c896977fea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters found:  {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'splitter': 'best'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.50      0.57        16\n",
      "           2       0.64      0.54      0.58        13\n",
      "           3       0.42      1.00      0.59         5\n",
      "           5       0.50      1.00      0.67         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       1.00      0.86      0.92         7\n",
      "\n",
      "    accuracy                           0.63        43\n",
      "   macro avg       0.54      0.65      0.56        43\n",
      "weighted avg       0.66      0.63      0.62        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train_c, y_train_c)\n",
    "\n",
    "print(\"\\nBest parameters found: \", grid_search.best_params_)\n",
    "\n",
    "best_dt = grid_search.best_estimator_\n",
    "y_pred = best_dt.predict(X_test_c)\n",
    "\n",
    "print(classification_report(y_test_c, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc70d48d-23e7-4481-a7eb-5df9600f2f84",
   "metadata": {},
   "source": [
    "# <b><span style='color:#ff6200'> Random Search</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67843014-4ee7-4fda-94cd-0cb7be113a46",
   "metadata": {},
   "source": [
    "Random Search is another hyperparameter optimization technique where, instead of exhaustively searching all possible combinations of hyperparameters, it randomly samples a specified number of combinations. This can be more efficient than Grid Search, especially when the hyperparameter space is large.\n",
    "\n",
    "## Procedure:\n",
    "- Define the range of values for each hyperparameter.\n",
    "- Specify the number of random combinations to sample.\n",
    "- Randomly sample combinations of hyperparameters.\n",
    "- Train and evaluate the model for each random combination using cross-validation.\n",
    "- Select the combination with the best performance.\n",
    "## Pros:\n",
    "- Less computationally expensive: More efficient than Grid Search, especially for large datasets and many hyperparameters.\n",
    "Can explore a larger hyperparameter space: Since it samples randomly, it can potentially find better hyperparameters by exploring a wider range.\n",
    "- Flexible: Does not require a predefined grid, allowing more flexibility in the search space.\n",
    "## Cons:\n",
    "- No guarantee of finding the best combination: It may not find the optimal set of hyperparameters since it doesn't exhaustively search all possible combinations.\n",
    "- Results can vary: Different runs of Random Search can yield different results due to the randomness in sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18375085-af41-4269-b804-3f9165ccbfa4",
   "metadata": {},
   "source": [
    "## <span style='color:#fcc36d'> For Regression </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af2cec5e-24ee-4817-a475-888624dceed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters found:  {'splitter': 'best', 'max_features': None, 'max_depth': 10, 'criterion': 'friedman_mse'}\n",
      "Mean Squared Error: 6.231533068951505\n",
      "R^2 Score: 0.9830694720714974\n"
     ]
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor()\n",
    "\n",
    "param_dist = {\n",
    "    'criterion': ['mse', 'friedman_mse', 'mae', 'poisson'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=dtr, param_distributions=param_dist, n_iter=100, cv=5, random_state=42)\n",
    "\n",
    "random_search.fit(X_train_r, y_train_r)\n",
    "\n",
    "print(\"\\nBest parameters found: \", random_search.best_params_)\n",
    "\n",
    "best_dtr = random_search.best_estimator_\n",
    "y_pred = best_dtr.predict(X_test_r)\n",
    "\n",
    "mse = mean_squared_error(y_test_r, y_pred)\n",
    "r2 = r2_score(y_test_r, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b2e445-a948-4d7c-848c-1bc60a3b2483",
   "metadata": {},
   "source": [
    "## <span style='color:#fcc36d'> For Classification </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bdbf75d-c1de-418c-a378-68dc5f14d4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters found:  {'splitter': 'best', 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.75      0.75        16\n",
      "           2       0.90      0.69      0.78        13\n",
      "           3       0.38      0.60      0.46         5\n",
      "           5       0.50      1.00      0.67         1\n",
      "           6       0.50      1.00      0.67         1\n",
      "           7       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.72        43\n",
      "   macro avg       0.67      0.79      0.69        43\n",
      "weighted avg       0.78      0.72      0.74        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "param_dist = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'max_features': [None, 'auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=dt, param_distributions=param_dist, n_iter=100, cv=5, random_state=42)\n",
    "\n",
    "random_search.fit(X_train_c, y_train_c)\n",
    "\n",
    "print(\"\\nBest parameters found: \", random_search.best_params_)\n",
    "\n",
    "best_dt = random_search.best_estimator_\n",
    "y_pred = best_dt.predict(X_test_c)\n",
    "\n",
    "print(classification_report(y_test_c, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c777c91b-098f-4c12-8f4c-f9eda1f960dd",
   "metadata": {},
   "source": [
    "# <b><span style='color:#ff6200'> Bayesian Optimization</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8940640-56f0-43f2-9a15-39ee714e1ae3",
   "metadata": {},
   "source": [
    "Bayesian Optimization is an efficient alternative to Grid Search for hyperparameter tuning. Instead of an exhaustive search, it uses probabilistic models to select the next set of hyperparameters to try based on past evaluations.\n",
    "\n",
    "## Procedure:\n",
    "\n",
    "- Define the range of values for each hyperparameter.\n",
    "- Create a probabilistic model to predict the performance of combinations.\n",
    "- Use this model to select the next combination of hyperparameters to evaluate.\n",
    "- Train and evaluate the model with the selected combination.\n",
    "- Update the probabilistic model based on the evaluation.\n",
    "- Repeat steps 3-5 until convergence or a stopping criterion is met.\n",
    "## Pros:\n",
    "\n",
    "- More efficient than Grid Search, especially with large datasets and many hyperparameters.\n",
    "- Utilizes information from previous evaluations to make better decisions on the next hyperparameters to try.\n",
    "## Cons:\n",
    "\n",
    "- More complex to understand and implement.\n",
    "- Requires more advanced libraries and methods (e.g., scikit-optimize, hyperopt, Optuna)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f886a-f905-44b6-9abf-b4ff15e4584f",
   "metadata": {},
   "source": [
    "## <span style='color:#fcc36d'> For Regression </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f44479c1-94c6-480e-9f7c-05747dbbcadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  OrderedDict({'max_depth': 29, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 6, 'splitter': 'random'})\n",
      "Mean Squared Error:  5.6554584903163105\n"
     ]
    }
   ],
   "source": [
    "param_space = {\n",
    "    'splitter': Categorical(['best', 'random']),\n",
    "    'max_depth': Integer(1, 50),\n",
    "    'min_samples_split': Integer(2, 20),\n",
    "    'min_samples_leaf': Integer(1, 20),\n",
    "    'max_features': Categorical([None, 'auto', 'sqrt', 'log2'])\n",
    "}\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "opt = BayesSearchCV(estimator=dt, search_spaces=param_space, n_iter=32, cv=5)\n",
    "\n",
    "opt.fit(X_train_r, y_train_r)\n",
    "\n",
    "print(\"Best parameters found: \", opt.best_params_)\n",
    "\n",
    "best_dt = opt.best_estimator_\n",
    "y_pred = best_dt.predict(X_test_r)\n",
    "\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_test_r, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026bcfe2-d07a-460c-8faf-662e459e5d02",
   "metadata": {},
   "source": [
    "## <span style='color:#fcc36d'> For Classification </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89308c5c-bee4-42bc-9268-0408379340bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  OrderedDict({'criterion': 'gini', 'max_depth': 50, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 8, 'splitter': 'best'})\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.81      0.72        16\n",
      "           2       0.86      0.46      0.60        13\n",
      "           3       0.14      0.20      0.17         5\n",
      "           5       0.33      1.00      0.50         1\n",
      "           6       1.00      1.00      1.00         1\n",
      "           7       1.00      0.71      0.83         7\n",
      "\n",
      "    accuracy                           0.63        43\n",
      "   macro avg       0.66      0.70      0.64        43\n",
      "weighted avg       0.71      0.63      0.64        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_space = {\n",
    "    'criterion': Categorical(['gini', 'entropy']),\n",
    "    'splitter': Categorical(['best', 'random']),\n",
    "    'max_depth': Integer(1, 50),\n",
    "    'min_samples_split': Integer(2, 20),\n",
    "    'min_samples_leaf': Integer(1, 20),\n",
    "    'max_features': Categorical([None, 'auto', 'sqrt', 'log2'])\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "opt = BayesSearchCV(estimator=dt, search_spaces=param_space, n_iter=32, cv=5)\n",
    "\n",
    "opt.fit(X_train_c, y_train_c)\n",
    "\n",
    "print(\"Best parameters found: \", opt.best_params_)\n",
    "\n",
    "best_dt = opt.best_estimator_\n",
    "y_pred = best_dt.predict(X_test_c)\n",
    "\n",
    "print(classification_report(y_test_c, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
